
# Set up

Import packages
```{r}
suppressPackageStartupMessages({
  suppressWarnings({
  library(tidyverse)   # Data wrangling
  library(here)        # File management
  library(readxl)      # Read excel files
  })})
```

Set settings and universal variables
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = here())
```

# Import data

Most recent draft of our network data
Downloaded from [box](https://berkeley.app.box.com/file/1987973103781?s=iy2wly7ej2heud3xzu2olsaj7qr0r5qd)
```{r}
network = read_excel("Data/Falldata_boxworking_sept16.xlsx")
```


SAFER clearinghouse data
This is an internal state water board dataset they shared with us for this project. All documentation is located in [this Google Drive folder](https://drive.google.com/drive/folders/1gxMrGeaOA_xtGb1zf97Z79EFEwKcIpCG).

Unfortunately there is no data dictionary, but [Jenny has worked on developing one](https://docs.google.com/spreadsheets/d/1ulStajU7D1eFu2m3V0fTDtcm3PGNlneX/edit?gid=631545570#gid=631545570).
```{r}
load("Data/Source/SAFER clearinghouse/safer_clearinghouse.RData")
```

# Clean data

Text cleaning of source names
```{r}
network = network%>%
  mutate(Source = gsub("\r\n", "", Source))
```

## Create source ID column
Use PWSID as source ID if source type is a PWS, otherwise generating a numerical source ID for each source (grouping by source name since there can be multiple rows with the same source)
```{r}
network = network%>%
  group_by(Source) %>%
  mutate(group_id = cur_group_id()) %>%
  ungroup() %>%
  mutate(source_id = ifelse(Source_type == "PWS", Source, group_id)) %>%
  select(-group_id)
```

Check to make sure it worked properly
```{r}
n_distinct(network$Source)
n_distinct(network$source_id)

network%>%
  group_by(Source)%>%
  filter(n_distinct(source_id) > 1)%>%
  arrange(Source)
```


## Missing lat/longs

Get df of sources with missing lat/longs
```{r}
missing_source_locations = network%>%
  filter(is.na(Source_lat) | is.na(Source_lon))
```

Filter clearinghouse data for facilities in PWSs with sources missing lat/longs
```{r}
clearinghouse_filtered = clearinghouse_raw%>%
  filter(cid %in% missing_source_locations$PWSID)%>%
  rename(clearinghouse_lat = latitude_measure, clearinghouse_long = longitude_measure)

rm(clearinghouse_raw)
```

Create function to identify similar source names across the network and clearinghouse datasets, based on jaro-winkler string distance
```{r}
# Create a function for fuzzy matching
fuzzy_match_sources <- function(missing_df, clearinghouse_df) {
  results <- list()
  
  for(i in 1:nrow(missing_df)) {
    current_pwsid <- missing_df$PWSID[i]
    current_source <- missing_df$Source[i]
    
    # Filter clearinghouse for exact PWSID match first
    potential_matches <- clearinghouse_df %>%
      filter(cid == current_pwsid)
    
    if(nrow(potential_matches) > 0) {
      # Calculate string distances
      distances <- stringdist::stringdist(
        tolower(current_source),
        tolower(potential_matches$facility_name),
        method = "jw"  # Jaro-Winkler is good for names
      )
      
      # Get the best match
      best_match_idx <- which.min(distances)
      best_distance <- min(distances)
      best_match <- potential_matches[best_match_idx, ]
      
      # Only consider it a match if similarity is good enough
      if(best_distance < 0.2) {  # Adjust threshold as needed
        results[[i]] <- data.frame(
          missing_PWSID = current_pwsid,
          missing_Source = current_source,
          matched_facility_name = best_match$facility_name,
          similarity_score = 1 - best_distance,  # Convert to similarity (0-1)
          clearinghouse_lat = best_match$clearinghouse_lat,  
          clearinghouse_long = best_match$clearinghouse_long,
          stringsAsFactors = FALSE)}}}
  
  return(bind_rows(results))}

# Run the matching
matched_locations <- fuzzy_match_sources(missing_source_locations, clearinghouse_filtered)

string_matches = missing_source_locations %>%
  select(Source,PWSID)%>%
  arrange(Source)%>%
  left_join(matched_locations, by = c("PWSID" = "missing_PWSID", "Source" = "missing_Source"))%>%
  filter(!is.na(matched_facility_name))
```


Generate key of missing locations and possible facility matches for manual review
```{r}
missing_key = missing_source_locations%>%
  select(PWSID, Source, Source_summary)%>%
  left_join(., clearinghouse_filtered%>%select(cid, facility_name)%>%unique(), by = c("PWSID" = "cid"))%>%
  rename(clearinghouse_facility_name = facility_name, source_name = Source)%>%
  mutate(string_match = ifelse(source_name %in% string_matches$Source & clearinghouse_facility_name %in% string_matches$matched_facility_name, 1, 0))

#write.csv(missing_key, "Data/Outputs/20250929_missing_lat_longs_clearinghouse_match_key.csv", row.names = F)
```

Manually match sources to clearinghouse facilities based on manual review with Kristin
```{r}
master_key = clearinghouse_filtered%>%
  rename(PWSID = cid, matched_facility_name = facility_name)%>%
  select(PWSID, matched_facility_name, clearinghouse_lat, clearinghouse_long)%>%
  unique()%>%
  mutate(Source = case_when(
    matched_facility_name == "BAJAMONT JUNCTION STRUCTURE-LANDIS 1,2,3" ~ "American River",
    matched_facility_name == "CATER TREATMENT PLANT RAW" ~ "Devil's Canyon Creek",
    matched_facility_name == "SWTP - RAW - STANDBY" ~ "North Canyon Creek",
    matched_facility_name == "SAN ANTONIO TUNNEL (SHAFT 6)" ~ "San Antonio Canyon Tunnel",
    matched_facility_name == "COLFAX WTP - RAW" ~ "North Fork American River",
    matched_facility_name == "ALTA WTP - RAW" ~ "North Fork American River",
    matched_facility_name == "BOARDMAN CANAL" & PWSID == "CA3110035" ~ "North Fork American River",
    matched_facility_name == "SPRING #2-MAIN" ~ "Hess Winery Main Spring",
    matched_facility_name == "SPRING #3-MIDDLE" ~ "Hess Winery Middle Spring",
    matched_facility_name == "GALLERY WELL" ~ "Nacimiento Reservoir",
    matched_facility_name == "SPRING 01" ~ "GRIER MUTUAL WATER COMPANY Spring",
    matched_facility_name == "RADIAL COLLECTOR WELL 01 - WOHLER SITE" ~ "Russian River",
    matched_facility_name == "OAK BIRCH COMPOSITE - RAW - INACTIVE" ~ "YUCAIPA VALLEY WATER DISTRICT Local Creeks",
    matched_facility_name == "WELL 04" ~ "Salinas River",
    matched_facility_name == "LOWER/VENTANA SPRING" ~ "VENTANA BIG SUR INN WS Lower Springs"))%>%
  filter(!is.na(Source))%>%
  arrange(matched_facility_name)%>%
  rbind(string_matches%>%select(-similarity_score))

master_key%>%arrange(matched_facility_name)
```

Join lat/longs from matched clearinghouse facilities back to network data
```{r}
missing_source_locations%>%
  select(PWSID, Source)%>%
  left_join(., master_key, by = c("Source", "PWSID"))

network%>%
  left_join(., master_key, by = c("Source", "PWSID"))%>%
  mutate(Source_lat = ifelse(is.na(Source_lat), clearinghouse_lat, Source_lat),
         Source_lon = ifelse(is.na(Source_lon), clearinghouse_long, Source_lon))%>%
  select(-c(matched_facility_name:clearinghouse_long))
```

## Project

Clean up project column and split into 3 separate dummy variables for 1) SWP, 2) CVP, and 3) Colorado.
Override if source type is another PWS (ex: either ‘purchased’ or NA)

```{r}
table(network$Project)

network = network%>%
  mutate(
    swp = case_when(
      Source_type == "PWS" ~ NA,
      grepl("SWP", Project) ~ 1,
      T ~ 0),
    cvp = case_when(
      Source_type == "PWS" ~ NA,
      grepl("CVP", Project) ~ 1,
      T ~ 0),
    colorado = case_when(
      Source_type == "PWS" ~ NA,
      grepl("Colorado|Coloardo", Project) ~ 1,
      T ~ 0))
```

For later: 
Take another look at rows with project marked as >1, revise if needed
Validation with lists of SWP/CVP contractors

```{r}
network%>%
  filter(swp + cvp + colorado > 1)
```




