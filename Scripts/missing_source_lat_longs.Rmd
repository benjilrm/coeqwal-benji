
# Set up

Import packages
```{r}
suppressPackageStartupMessages({
  suppressWarnings({
  library(tidyverse)   # Data wrangling
  library(here)        # File management
  library(readxl)      # Read excel files
  })})
```

Set settings and universal variables
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = here())
```

# Import data

Cleaned & deduplicated network data
```{r}
network = read.csv("Data/Outputs/20251002_network_data_cleaned.csv")
```


SAFER clearinghouse data
This is an internal state water board dataset they shared with us for this project. All documentation is located in [this Google Drive folder](https://drive.google.com/drive/folders/1gxMrGeaOA_xtGb1zf97Z79EFEwKcIpCG).

Unfortunately there is no data dictionary, but [Jenny has worked on developing one](https://docs.google.com/spreadsheets/d/1ulStajU7D1eFu2m3V0fTDtcm3PGNlneX/edit?gid=631545570#gid=631545570).
```{r}
load("Data/Source/SAFER clearinghouse/safer_clearinghouse.RData")
```


## Missing lat/longs

Get df of sources with missing lat/longs
```{r}
missing_source_locations = network%>%
  filter(is.na(Source_lat) | is.na(Source_lon))
```

Filter clearinghouse data for facilities in PWSs with sources missing lat/longs
```{r}
clearinghouse_filtered = clearinghouse_raw%>%
  filter(cid %in% missing_source_locations$PWSID)%>%
  rename(clearinghouse_lat = latitude_measure, clearinghouse_long = longitude_measure)

rm(clearinghouse_raw)
```

Create function to identify similar source names across the network and clearinghouse datasets, based on jaro-winkler string distance
```{r}
# Create a function for fuzzy matching
fuzzy_match_sources <- function(missing_df, clearinghouse_df) {
  results <- list()
  
  for(i in 1:nrow(missing_df)) {
    current_pwsid <- missing_df$PWSID[i]
    current_source <- missing_df$Source[i]
    
    # Filter clearinghouse for exact PWSID match first
    potential_matches <- clearinghouse_df %>%
      filter(cid == current_pwsid)
    
    if(nrow(potential_matches) > 0) {
      # Calculate string distances
      distances <- stringdist::stringdist(
        tolower(current_source),
        tolower(potential_matches$facility_name),
        method = "jw"  # Jaro-Winkler is good for names
      )
      
      # Get the best match
      best_match_idx <- which.min(distances)
      best_distance <- min(distances)
      best_match <- potential_matches[best_match_idx, ]
      
      # Only consider it a match if similarity is good enough
      if(best_distance < 0.2) {  # Adjust threshold as needed
        results[[i]] <- data.frame(
          missing_PWSID = current_pwsid,
          missing_Source = current_source,
          matched_facility_name = best_match$facility_name,
          similarity_score = 1 - best_distance,  # Convert to similarity (0-1)
          clearinghouse_lat = best_match$clearinghouse_lat,  
          clearinghouse_long = best_match$clearinghouse_long,
          stringsAsFactors = FALSE)}}}
  
  return(bind_rows(results))}

# Run the matching
matched_locations <- fuzzy_match_sources(missing_source_locations, clearinghouse_filtered)

string_matches = missing_source_locations %>%
  select(Source,PWSID)%>%
  arrange(Source)%>%
  left_join(matched_locations, by = c("PWSID" = "missing_PWSID", "Source" = "missing_Source"))%>%
  filter(!is.na(matched_facility_name))
```


Generate key of missing locations and possible facility matches for manual review
```{r}
missing_key = missing_source_locations%>%
  select(PWSID, Source, Source_summary)%>%
  left_join(., clearinghouse_filtered%>%select(cid, facility_name)%>%unique(), by = c("PWSID" = "cid"))%>%
  rename(clearinghouse_facility_name = facility_name, source_name = Source)%>%
  mutate(string_match = ifelse(source_name %in% string_matches$Source & clearinghouse_facility_name %in% string_matches$matched_facility_name, 1, 0))

#write.csv(missing_key, "Data/Outputs/20250929_missing_lat_longs_clearinghouse_match_key.csv", row.names = F)
```

Manually match sources to clearinghouse facilities based on manual review with Kristin
```{r}
master_key = clearinghouse_filtered%>%
  rename(PWSID = cid, matched_facility_name = facility_name)%>%
  select(PWSID, matched_facility_name, clearinghouse_lat, clearinghouse_long)%>%
  unique()%>%
  mutate(Source = case_when(
    matched_facility_name == "BAJAMONT JUNCTION STRUCTURE-LANDIS 1,2,3" ~ "American River",
    matched_facility_name == "CATER TREATMENT PLANT RAW" ~ "Devil's Canyon Creek",
    matched_facility_name == "SWTP - RAW - STANDBY" ~ "North Canyon Creek",
    matched_facility_name == "SAN ANTONIO TUNNEL (SHAFT 6)" ~ "San Antonio Canyon Tunnel",
    matched_facility_name == "COLFAX WTP - RAW" ~ "North Fork American River",
    matched_facility_name == "ALTA WTP - RAW" ~ "North Fork American River",
    matched_facility_name == "BOARDMAN CANAL" & PWSID == "CA3110035" ~ "North Fork American River",
    matched_facility_name == "SPRING #2-MAIN" ~ "HESS WINERY Main Spring",
    matched_facility_name == "SPRING #3-MIDDLE" ~ "HESS WINERY Middle Spring",
    matched_facility_name == "GALLERY WELL" ~ "Nacimiento Reservoir",
    matched_facility_name == "SPRING 01" ~ "GRIER MUTUAL WATER COMPANY Spring",
    matched_facility_name == "RADIAL COLLECTOR WELL 01 - WOHLER SITE" ~ "Russian River",
    matched_facility_name == "OAK BIRCH COMPOSITE - RAW - INACTIVE" ~ "YUCAIPA VALLEY WATER DISTRICT Local Creeks",
    matched_facility_name == "WELL 04" ~ "Salinas River",
    matched_facility_name == "LOWER/VENTANA SPRING" ~ "VENTANA BIG SUR INN WS Lower Springs"))%>%
  filter(!is.na(Source))%>%
  arrange(matched_facility_name)%>%
  rbind(string_matches%>%select(-similarity_score))
```

# Export
```{r}
write.csv(master_key, "Data/Outputs/20251002_missing_source_lat_long_key.csv", row.names = F)
```







