

# Set up

Import packages
```{r}
suppressPackageStartupMessages({
  suppressWarnings({
  library(tidyverse)   # Data wrangling
  library(here)        # File management
  library(readxl)      # Read excel files
  library(igraph)      # Network analysis
  })})
```

Set settings and universal variables
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = here())
```

# Import data

Cleaned & deduplicated network data
```{r}
network = read_excel("data/Source/Network data/Final data 10.27.25 latlon comp.xlsx", na = "NA")
```


# Cleaning and processing

- Remove columns we definitely don't need
- Rename columns and reorder remaining columns
- Convert any columns with 0/1 to No/Yes, or in the case of gw, combine both columns into one categorical column
- Add new column for system size based on population served (thresholds provided by Kristin)
- Clean up errors in source type column
- Standardise all source lat/longs (there are currently different values for the same source)

```{r}
network_master = network%>%
  rename(pop_served = Population_served_count, source_name = Source)%>%
  rename_with(tolower)%>%
  
  mutate(
    purchased = case_when(
      purchased == "Yes" ~ 1,
      purchased == "No" ~ 0,
      T ~ NA),
    pop_served = ifelse(pop_served <= 1, NA, pop_served),
    system_size = case_when(
      is.na(pop_served) ~ NA,
      pop_served > 100000 ~ "Very Large",
      pop_served > 10000 ~ "Large",
      pop_served > 3300 ~ "Medium",
      pop_served > 500 ~ "Small",
      pop_served <= 500 ~ "Very Small"),
    source_type = case_when(
      source_name == "Kern River" ~ "River",
      source_name == "Lake Havasu" ~ "Lake",
      source_name == "Lake Spaulding" ~ "Lake",
      T ~ source_type))%>%
  
  group_by(source_name)%>%
  mutate(num_systems_served = n())%>%
  ungroup()%>%
  
  group_by(pwsid)%>%
  mutate(num_sw_sources = n())%>%
  ungroup()%>%

  select(-c(system_lat:system_lon, source_lat:source_lon, is_wholesaler, source_number, source_summary, combined_source_notes, combined_calsim_notes, swp:colorado_incompleteandnotedited, x2020_ccr_percent:x2023_percent, summer_2025_cleaning, calsim_demandunit:calsim_notes_sept2025, colorado_loop, gw_access_no_cc:gw_compliant_w_dw_standards_no_cc, connection_id, source_id))%>%
  
  select(1:3,5,4,13,15, 6:7,14, 8:12)%>%
  rename(swp = swp_loop, cvp = cvp_loop)
```


# Create network data


## Nodes 

Systems
Keep one row per system
```{r}
system_nodes = network_master%>%
  select(system_name:num_sw_sources)%>%
  unique()%>%
  rename(id = pwsid)

table(system_nodes$system_size)
```

Sources
Keep one row per source. Exclude any PWS sources since these will be in the systems dataset.
```{r}
source_nodes = network_master %>%
  select(source_name:num_systems_served) %>%
  unique()%>%
  rename(id = source_name)
```

Combine

```{r}
all_nodes = full_join(source_nodes, system_nodes, by = "id")%>%
  mutate(type = ifelse(is.na(system_name), "source", "system"))
```



## Edges

Convert dataframe to igraph object (bipartite network)
```{r}
network_edges = network_master%>%
  select(source_name, pwsid)

network = graph_from_data_frame(network_edges, vertices = all_nodes, directed = T)
is_bipartite(network)

E(network)$average_source_usage = network_master$average_source_usage[match(
  paste(network_master$source_name, network_master$pwsid, sep = "|"),
  paste(ends(network, E(network))[,1], ends(network, E(network))[,2], sep = "|"))]
```

# Analysis

## Centrality

In, out, and total degree centrality for systems
```{r}
system_centrality = all_nodes%>%
  filter(type == "system")%>%
  rename(in_degree = num_sw_sources,
         out_degree = num_systems_served,
         pwsid = id)%>%
  mutate(
    out_degree = replace_na(out_degree, 0),
    total_degree = in_degree + out_degree)%>%
  arrange(-total_degree)%>%
  select(1,4,9,3,11,5:8)
```

Calculate betweenness centrality - systems that are major redistribution hubs (ie: measure of centrality based on shortest paths that pass through a given node)
```{r}
betweenness_all = betweenness(network, directed = TRUE)
system_centrality$betweenness = betweenness_all[V(network)$type == "system"]

system_centrality
```

In-Degree
```{r}
system_centrality%>%
  group_by(system_size)%>%
  reframe(in_degree = mean(in_degree, na.rm = T))%>%
  #filter(!is.na(system_size))%>%
  mutate(system_size = factor(system_size, levels = c("Very Small", "Small", "Medium", "Large", "Very Large")))%>%
  ggplot(aes(x = system_size, y = in_degree, fill = system_size))+
  geom_bar(stat = "identity")+
  theme_bw()+
  labs(x = "System Size", y = "Mean In-Degree Centrality")+
  theme(legend.position = "none")

system_centrality%>%
  mutate(system_size = factor(system_size, levels = c("Very Small", "Small", "Medium", "Large", "Very Large")))%>%
  ggplot(aes(x = system_size, y = in_degree, fill = system_size))+
  geom_boxplot()+
  theme_bw()+
  labs(x = "System Size", y = "In-Degree Centrality")+
  theme(legend.position = "none")
```

Other degree
```{r}
ggplot(system_centrality, aes(total_degree))+
  geom_histogram(fill = "coral2", colour = "black")+
  theme_bw()

system_centrality%>%
  group_by(system_size)%>%
  reframe(total_degree = mean(total_degree, na.rm = T))%>%
  mutate(system_size = factor(system_size, levels = c("Very Small", "Small", "Medium", "Large", "Very Large")))%>%
  ggplot(aes(x = system_size, y = total_degree, fill = system_size))+
  geom_bar(stat = "identity")+
  theme_bw()+
  labs(x = "System Size", y = "Total Degree Centrality")+
  theme(legend.position = "none")+
  scale_y_log10()

system_centrality%>%
  group_by(system_size)%>%
  reframe(betweenness = mean(betweenness, na.rm = T))%>%
  #filter(!is.na(system_size))%>%
  mutate(system_size = factor(system_size, levels = c("Very Small", "Small", "Medium", "Large", "Very Large")))%>%
  ggplot(aes(x = system_size, y = betweenness, fill = system_size))+
  geom_bar(stat = "identity")+
  theme_bw()+
  labs(x = "System Size", y = "Mean Betweenness Centrality")+
  theme(legend.position = "none")

system_centrality%>%
  mutate(system_size = factor(system_size, levels = c("Very Small", "Small", "Medium", "Large", "Very Large")))%>%
  ggplot(aes(x = system_size, y = betweenness, fill = system_size))+
  geom_boxplot()+
  theme_bw()+
  labs(x = "System Size", y = "Betweenness Centrality")+
  theme(legend.position = "none")+
  scale_y_log10()
```

Out degree centrality for sources
```{r}
source_centrality = all_nodes%>%
  rename(source_name = id, out_degree = num_systems_served)%>%
  filter(type == "source")%>%
  arrange(-out_degree)%>%
  select(1:3)

ggplot(source_centrality, aes(out_degree))+
  geom_histogram(fill = "coral2", colour = "black")+
  theme_bw()
```

# Path length

Calculate shortest paths from sources to systems
```{r}
sources = V(network)[type == "source"]
systems = V(network)[type == "system"]

# Get shortest paths from all sources to all systems
path_length_matrix = distances(network, v = sources, to = systems, mode = "out")
path_lengths = as.vector(path_length_matrix[is.finite(as.vector(path_length_matrix))])
```

Summary stats for sources' path lengths
```{r}
data.frame(
  source_id = sources$name,
  source_type = V(network)[sources]$source_type,
  mean_path_length = apply(path_length_matrix, 1, function(x) mean(x[is.finite(x)])),
  median_path_length = apply(path_length_matrix, 1, function(x) median(x[is.finite(x)])),
  max_path_length = apply(path_length_matrix, 1, function(x) max(x[is.finite(x)])),
  min_path_length = apply(path_length_matrix, 1, function(x) min(x[is.finite(x)])),
  n_reachable_systems = apply(path_length_matrix, 1, function(x) sum(is.finite(x))))%>%
  arrange(-mean_path_length)
```

Summary stats for systems' path lengths

Right now, this is ONLY when systems are the final node on a path
```{r}
system_path_lengths = data.frame(
  pwsid = systems$name,
  system_size = V(network)[systems]$system_size,
  provider_type = V(network)[systems]$provider_type,
  mean_path_length = apply(path_length_matrix, 2, function(x) mean(x[is.finite(x)])),
  median_path_length = apply(path_length_matrix, 2, function(x) median(x[is.finite(x)])),
  max_path_length = apply(path_length_matrix, 2, function(x) max(x[is.finite(x)])),
  min_path_length = apply(path_length_matrix, 2, function(x) min(x[is.finite(x)])),
  n_reachable_sources = apply(path_length_matrix, 2, function(x) sum(is.finite(x))))%>%
  arrange(-max_path_length)
  #left_join(., system_nodes, by = c("pwsid" = "id"))
  
system_path_lengths

system_path_lengths%>%
  group_by(system_size)%>%
  reframe(mean_path_length = mean(mean_path_length, na.rm = T))%>%
  #filter(!is.na(system_size))%>%
  mutate(system_size = factor(system_size, levels = c("Very Small", "Small", "Medium", "Large", "Very Large")))%>%
  ggplot(aes(x = system_size, y = mean_path_length, fill = system_size))+
  geom_bar(stat = "identity")+
  theme_bw()+
  labs(x = "System Size", y = "Mean Path Length")+
  theme(legend.position = "none")

system_path_lengths%>%
  mutate(system_size = factor(system_size, levels = c("Very Small", "Small", "Medium", "Large", "Very Large")))%>%
  ggplot(aes(x = system_size, y = mean_path_length, fill = system_size))+
  geom_boxplot()+
  theme_bw()+
  labs(x = "System Size", y = "Path Length")+
  theme(legend.position = "none")
```

# Source diversity

```{r}
# Calculate HHI for each system
system_diversity = sapply(systems, function(system) {
  # Get edges going into this system (sources supplying it)
  incoming_edges = E(network)[.to(system)]
  
  if (length(incoming_edges) == 0) return(NA)  # no sources
  
  # Get the usage percentages for this system's sources
  usage_percentages = incoming_edges$average_source_usage/100
  
  # Calculate HHI (sum of squares of market shares, scaled 0-10000)
  hhi = sum((usage_percentages * 100)^2)
  
  return(hhi)})

# Create a diversity data frame
diversity_df = data.frame(
  system_id = systems$name,
  system_size = V(network)[systems]$system_size,
  hhi = system_diversity,
  stringsAsFactors = FALSE,
  row.names = NULL)

diversity_df%>%
  group_by(system_size)%>%
  reframe(hhi = mean(hhi, na.rm = T))%>%
  #filter(!is.na(system_size))%>%
  mutate(system_size = factor(system_size, levels = c("Very Small", "Small", "Medium", "Large", "Very Large")))%>%
  ggplot(aes(x = system_size, y = hhi, fill = system_size))+
  geom_bar(stat = "identity")+
  theme_bw()+
  labs(x = "System Size", y = "Mean HHI")+
  theme(legend.position = "none")

diversity_df%>%
  mutate(system_size = factor(system_size, levels = c("Very Small", "Small", "Medium", "Large", "Very Large")))%>%
  ggplot(aes(x = system_size, y = hhi, fill = system_size))+
  geom_boxplot()+
  theme_bw()+
  labs(x = "System Size", y = "HHI")+
  theme(legend.position = "none")
```
Kristin also mentioned [participation coefficient](https://www.google.com/url?q=https://www.nature.com/articles/s41467-017-01189-w%23:~:text%3DParticipation%2520coefficient,-Given%2520a%2520particular%26text%3Dwhere%2520%257BK_i%257D%2520is%2520the%2520sum,are%2520to%2520a%2520single%2520community&sa=D&source=docs&ust=1762796373372331&usg=AOvVaw3DkgsUakhBdOK-fW7kOtPS). 
Seems like there are options to calculate it in R [example](https://search.r-project.org/CRAN/refmans/NetworkToolbox/html/participation.html)

# Local density / cluster / community
Kristin's hypothesis: on average, small systems will have less local density than large systems
How can we test?


# Bipartite project

Create one-mode projection on systems (systems connected if they share sources)
```{r}
system_adjacency = bipartite.projection(network)$proj2

# Degree in the projection = number of other systems sharing sources
system_shared_sources_degree = degree(system_adjacency)
system_degrees$shared_sources_degree = system_shared_sources_degree
```




